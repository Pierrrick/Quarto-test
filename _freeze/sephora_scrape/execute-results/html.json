{
  "hash": "15f5b1b869c45279973a22513a3837b5",
  "result": {
    "markdown": "---\ntitle: \"Scrape Sephora\"\n---\n\n```{pyth Scraping sephora.fr, eval=FALSE}\nimport logging\nimport re\nimport requests\nimport csv\nfrom bs4 import BeautifulSoup\n\n\ndef get(uri):\n    logging.info(f'Will query: {uri}')\n    headers = {'User-Agent': 'Mozilla/5.0'}\n    r = requests.get(uri, headers=headers)\n    r.raise_for_status()\n    r.encoding = 'UTF-8'\n    return r\n\n\ndef get_soup(uri: str) -> BeautifulSoup:\n    r = get(uri)\n    return BeautifulSoup(r.text, 'html.parser')\n\ndef main():\n    host = \"https://www.sephora.fr\"\n    path = \"/shop/cheveux/soin-cheveux/shampoing-c447/\"\n    uri = host + path\n    soup = get_soup(uri)\n\n    with open('sephora_data.csv', 'w', newline='\\n',encoding=\"utf-8\") as csvfile:\n        writer = csv.writer(csvfile, delimiter=',')\n        writer.writerow(['ingredients', 'brand', 'name', 'price', 'quantity', 'unit'])\n\n\n        expected_article_amount = soup.find('div', {'class': 'results-hits'}).text.split()[0]\n        logging.info(f'Will get {expected_article_amount} of articles.')\n        all_articles_uri = f'{host}{path}?srule=GoLiveSortingRule&sz={expected_article_amount}&format=page-element&start=0&on=onclickload'\n        soup = get_soup(all_articles_uri)\n        articles = soup.find_all('div', attrs={'class': 'product-info-wrapper'})\n        logging.info(f'Got {len(articles)} articles.')\n        for article in articles:\n            article_product_link = article.find('a', attrs={'class': 'product-tile-link'} )['href']\n            article_soup = get_soup(article_product_link)\n            brand = article_soup.find('a', {'class': 'brand-link'}).text.replace('\\n', '')\n            name = article_soup.find('span', {'class': 'product-name product-name-bold'}).text.replace('\\n', '')\n            try:\n                ingredients = article_soup.find('div', {'class': 'accordion-content ingredients-content'}).text.replace('\\n','').split('.')[0]\n                ingredients = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", ingredients)\n            except Exception as e:\n                logging.error(\"Couldn't find the ingredients\")\n                continue\n            try:\n                # unit contains the price and price the unit (go figure, I guess they are not talented enough)\n                price = article_soup.find('span', {'class': 'unit'}).text.replace('\\n', '').replace(' â‚¬', '')\n                quantity, unit = article_soup.find('span', {'class': 'price'}).text.replace('\\n', '').replace('ml', ' ml').split()\n            except Exception as e:\n                logging.error(\"Couldn't find the price or unit \")\n                continue\n\n            writer.writerow([ingredients, brand, name, price, quantity, unit])\n\n\nif __name__ == '__main__':\n    logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n    main()\n```\n\n",
    "supporting": [
      "sephora_scrape_files"
    ],
    "filters": [],
    "includes": {}
  }
}
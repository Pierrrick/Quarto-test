[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A propos de ce site.\n\n\n\n\n\n\n\nowo\n\n\n\nJe te vois Tsara"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Site de Test",
    "section": "",
    "text": "About"
  },
  {
    "objectID": "sephora_scrape.html",
    "href": "sephora_scrape.html",
    "title": "Scrape Sephora",
    "section": "",
    "text": "```{pyth Scraping sephora.fr, eval=FALSE} import logging import re import requests import csv from bs4 import BeautifulSoup\ndef get(uri): logging.info(f’Will query: {uri}‘) headers = {’User-Agent’: ‘Mozilla/5.0’} r = requests.get(uri, headers=headers) r.raise_for_status() r.encoding = ‘UTF-8’ return r\ndef get_soup(uri: str) -&gt; BeautifulSoup: r = get(uri) return BeautifulSoup(r.text, ‘html.parser’)\ndef main(): host = “https://www.sephora.fr” path = “/shop/cheveux/soin-cheveux/shampoing-c447/” uri = host + path soup = get_soup(uri)\nwith open('sephora_data.csv', 'w', newline='\\n',encoding=\"utf-8\") as csvfile:\n    writer = csv.writer(csvfile, delimiter=',')\n    writer.writerow(['ingredients', 'brand', 'name', 'price', 'quantity', 'unit'])\n\n\n    expected_article_amount = soup.find('div', {'class': 'results-hits'}).text.split()[0]\n    logging.info(f'Will get {expected_article_amount} of articles.')\n    all_articles_uri = f'{host}{path}?srule=GoLiveSortingRule&sz={expected_article_amount}&format=page-element&start=0&on=onclickload'\n    soup = get_soup(all_articles_uri)\n    articles = soup.find_all('div', attrs={'class': 'product-info-wrapper'})\n    logging.info(f'Got {len(articles)} articles.')\n    for article in articles:\n        article_product_link = article.find('a', attrs={'class': 'product-tile-link'} )['href']\n        article_soup = get_soup(article_product_link)\n        brand = article_soup.find('a', {'class': 'brand-link'}).text.replace('\\n', '')\n        name = article_soup.find('span', {'class': 'product-name product-name-bold'}).text.replace('\\n', '')\n        try:\n            ingredients = article_soup.find('div', {'class': 'accordion-content ingredients-content'}).text.replace('\\n','').split('.')[0]\n            ingredients = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", ingredients)\n        except Exception as e:\n            logging.error(\"Couldn't find the ingredients\")\n            continue\n        try:\n            # unit contains the price and price the unit (go figure, I guess they are not talented enough)\n            price = article_soup.find('span', {'class': 'unit'}).text.replace('\\n', '').replace(' €', '')\n            quantity, unit = article_soup.find('span', {'class': 'price'}).text.replace('\\n', '').replace('ml', ' ml').split()\n        except Exception as e:\n            logging.error(\"Couldn't find the price or unit \")\n            continue\n\n        writer.writerow([ingredients, brand, name, price, quantity, unit])\nif name == ‘main’: logging.basicConfig(format=‘%(levelname)s:%(message)s’, level=logging.INFO) main() ```"
  }
]